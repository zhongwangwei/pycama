#!/usr/bin/env python3
"""
Grid Routing Initialization - Main Program
Reads namelist.input and generates all region and parameter files
"""
import sys
import os
import shutil
import traceback
import argparse
from configparser import ConfigParser

from .namelist import Namelist
from .region_tools import RegionProcessor
from .param_tools import ParamProcessor
from .validation import validate_inputs, ValidationError


def print_header(text):
    """Print formatted header"""
    print("\n" + "=" * 70)
    print(text)
    print("=" * 70)


def is_global_domain(west, east, south, north, tolerance=0.01):
    """
    Check if the domain covers the entire globe

    Args:
        west, east, south, north: Domain boundaries
        tolerance: Tolerance for floating point comparison (degrees)

    Returns:
        True if global domain, False otherwise
    """
    is_global_lon = (abs(west - (-180.0)) <= tolerance and abs(east - 180.0) <= tolerance)
    is_global_lat = (abs(south - (-90.0)) <= tolerance and abs(north - 90.0) <= tolerance)

    return is_global_lon and is_global_lat


def copy_global_map_files(global_map_dir, output_dir, case_name=None):
    """
    Copy global map files directly to output directory
    This is used when processing global domain (no regional cutting needed)

    Args:
        global_map_dir: Source directory with global map files
        output_dir: Destination directory
        case_name: Case name for naming inpmat files
    """
    # BUG FIX #2: Validate directory existence
    if not os.path.exists(global_map_dir):
        raise FileNotFoundError(
            f"Global map directory not found: {global_map_dir}\n"
            f"Please check your namelist.input configuration."
        )
    if not os.path.isdir(global_map_dir):
        raise ValueError(
            f"Global map path is not a directory: {global_map_dir}"
        )

    # BUG FIX #6: Handle case_name=None
    if case_name is None:
        case_name = "global"
        print(f"NOTE: case_name not provided, using default: '{case_name}'")

    print("\n" + "=" * 70)
    print("GLOBAL MODE: Copying files from global map directory")
    print("=" * 70)

    # BUG FIX #7: Move lsmask.bin to optional files (it's generated, not source)
    # List of essential files to copy
    essential_files = [
        'params.txt', 'nextxy.bin', 'nextxy_noedge.bin', 'downxy.bin',
        'elevtn.bin', 'ctmare.bin', 'grdare.bin', 'uparea.bin',
        'lonlat.bin', 'nxtdst.bin', 'rivlen.bin', 'width.bin', 'fldhgt.bin',
        'rivseq.bin', 'uparea_grid.bin', 'upgrid.bin', 'nxtdst_grid.bin',
        'rivlen_grid.bin', 'basin.bin', 'bsncol.bin'
    ]

    # Optional files (may not exist in source directory)
    optional_files = [
        'bifori.txt', 'bifprm.txt', 'bifdph.bin', 'lsmask.bin'
    ]

    # BUG FIX #1: Find FIRST matching inpmat/diminfo file only (avoid multiple files)
    inpmat_file = None
    diminfo_file = None

    # Search for inpmat and diminfo files (sorted for deterministic behavior)
    for fname in sorted(os.listdir(global_map_dir)):
        # Find first inpmat file
        if inpmat_file is None and fname.startswith('inpmat_') and fname.endswith('.bin'):
            inpmat_file = fname
        # Find first diminfo file
        if diminfo_file is None and fname.startswith('diminfo_') and fname.endswith('.txt'):
            diminfo_file = fname
        # Stop early if both found
        if inpmat_file is not None and diminfo_file is not None:
            break

    copied_count = 0
    skipped_count = 0

    # Copy essential files
    for filename in essential_files:
        src_file = os.path.join(global_map_dir, filename)
        dst_file = os.path.join(output_dir, filename)

        if os.path.exists(src_file):
            print(f"  Copying: {filename}")
            shutil.copy2(src_file, dst_file)
            copied_count += 1
        else:
            print(f"  ERROR: Essential file not found: {filename}")
            skipped_count += 1

    # BUG FIX #4: Fail if essential files are missing
    if skipped_count > 0:
        raise FileNotFoundError(
            f"Failed to copy {skipped_count} essential file(s) from global map directory.\n"
            f"Missing files prevent proper initialization.\n"
            f"Please ensure all required files exist in: {global_map_dir}"
        )

    # Copy optional files (no warning if missing)
    for filename in optional_files:
        src_file = os.path.join(global_map_dir, filename)
        dst_file = os.path.join(output_dir, filename)

        if os.path.exists(src_file):
            print(f"  Copying: {filename}")
            shutil.copy2(src_file, dst_file)
            copied_count += 1

    # NOTE: inpmat and diminfo files are NOT copied here because:
    # - If run_inpmat=True, new inpmat file will be generated by generate_inpmat
    # - If run_params=True, new diminfo.txt will be generated by calc_outclm
    # - Copying old files would be overwritten anyway
    print(f"  Skipped: inpmat and diminfo files (will be generated if needed)")

    # Copy high-resolution directories if they exist
    hires_dirs = ['1min', '30sec', '15sec', '3sec']
    for hires_dir in hires_dirs:
        src_hires = os.path.join(global_map_dir, hires_dir)
        dst_hires = os.path.join(output_dir, hires_dir)

        if os.path.exists(src_hires) and os.path.isdir(src_hires):
            print(f"  Copying directory: {hires_dir}/")
            # BUG FIX #8: Use safer directory copy to avoid race conditions
            try:
                # First try: remove and copy
                if os.path.exists(dst_hires):
                    shutil.rmtree(dst_hires)
                shutil.copytree(src_hires, dst_hires)
            except FileExistsError:
                # Race condition: directory created between rmtree and copytree
                # Retry once
                shutil.rmtree(dst_hires)
                shutil.copytree(src_hires, dst_hires)
            copied_count += 1

    print(f"\n  Copied {copied_count} files/directories")
    print("\n✓ Global map files copied successfully!")


def run_region_generation(nml, global_map_dir, output_dir, case_name, run_bifurcation=False, run_inpmat=True):
    """
    Generate regional map files and input matrix
    For global domain: directly copy files from global_map_dir (unless force_regional_mode=True)
    For regional domain: cut_domain + set_map + [cut_bifway] + generate_inpmat
    """
    # ========================================================================
    # STEP 0: Validate all inputs before processing
    # ========================================================================
    try:
        global_map_dir, output_dir = validate_inputs(
            nml, global_map_dir, output_dir, run_inpmat
        )
    except ValidationError as e:
        print(f"\n❌ INPUT VALIDATION FAILED\n")
        print(str(e))
        print("\nPlease fix the errors above and try again.")
        return False

    # Get domain parameters
    west = nml.get('RiverMap_Gen', 'west')
    east = nml.get('RiverMap_Gen', 'east')
    south = nml.get('RiverMap_Gen', 'south')
    north = nml.get('RiverMap_Gen', 'north')

    # Check if this is a global domain
    is_global = is_global_domain(west, east, south, north)

    # Check if user wants to force regional processing even for global domain
    force_regional_mode = nml.get('RiverMap_Gen', 'force_regional_mode', False)

    # Override global mode if force_regional_mode is True
    if is_global and force_regional_mode:
        print("\n*** GLOBAL DOMAIN DETECTED ***")
        print("*** force_regional_mode=True: Using regional processing instead of direct copy ***")
        print("*** This allows comparison between global mode and regional mode ***")
        is_global = False  # Treat as regional to force full processing

    if is_global:
        header_text = "GLOBAL DOMAIN MODE (copying files directly)"
    else:
        header_text = "REGION GENERATION (cut_domain + set_map"
        if run_bifurcation:
            header_text += " + cut_bifway"
        header_text += " + generate_inpmat)"

    print_header(header_text)

    print(f"\nDomain: [{west}, {east}] x [{south}, {north}] degrees")
    print(f"Global map: {global_map_dir}")
    print(f"Output: {output_dir}")

    if is_global:
        print("\n*** GLOBAL DOMAIN DETECTED ***")
        print("Skipping regional processing (cut_domain, set_map, cut_bifway)")
        print("Copying files directly from global map directory")

    # Initialize processor
    region_proc = RegionProcessor(config=None)

    try:
        if is_global:
            # GLOBAL MODE: Copy files directly
            copy_global_map_files(global_map_dir, output_dir, case_name)

            # For global mode, high-resolution directories are already copied
            # So we skip combine_hires
            # Note: inpmat files are also copied with custom naming based on case_name

            # BUG FIX #3: Check if hires data exists when run_inpmat=True
            if run_inpmat:
                hires_tag = nml.get('RiverMap_Gen', 'hires_tag', '1min')
                hires_dst = os.path.join(output_dir, hires_tag)
                location_file = os.path.join(hires_dst, 'location.txt')

                if not os.path.exists(location_file):
                    raise FileNotFoundError(
                        f"\nCannot generate input matrix: high-resolution data not found.\n"
                        f"Missing: {location_file}\n\n"
                        f"The global map directory does not contain '{hires_tag}/' directory,\n"
                        f"which is required for generate_inpmat.\n\n"
                        f"Solutions:\n"
                        f"  1. Set run_inpmat=False in namelist.input to use existing inpmat files\n"
                        f"  2. Ensure '{hires_tag}/' directory exists in: {global_map_dir}"
                    )

        else:
            # REGIONAL MODE: Process as before
            # Step 1: Cut domain from global map
            print("\n" + "-" * 70)
            print("Step 1: cut_domain (extract regional domain)")
            print("-" * 70)
            region_proc.cut_domain(
                global_dir=global_map_dir,
                west=west,
                east=east,
                north=north,
                south=south,
                output_dir=output_dir
            )

            # Step 2: Generate derived maps
            print("\n" + "-" * 70)
            print("Step 2: set_map (calculate derived properties)")
            print("-" * 70)
            region_proc.set_map(output_dir)

            # Step 3: Cut bifurcation pathways (optional)
            if run_bifurcation:
                print("\n" + "-" * 70)
                print("Step 3: cut_bifway (extract bifurcation pathways)")
                print("-" * 70)
                region_proc.cut_bifway(
                    global_map_dir=global_map_dir,
                    output_dir=output_dir
                )

            # Step 3.5: Combine high-resolution data (required for generate_inpmat)
            if run_inpmat:
                print("\n" + "-" * 70)
                print("Step 3.5: combine_hires (prepare high-resolution data)")
                print("-" * 70)

                # Get hires tag from RIVER_PARAMS section (default: 1min)
                hires_tag = nml.get('RiverMap_Gen', 'hires_tag', '1min')

                # Run combine_hires to create regional high-resolution data
                region_proc.combine_hires(
                    output_dir=output_dir,
                    global_map_dir=global_map_dir,
                    hires_tag=hires_tag
                )

        # Step 4: Generate input matrix for runoff interpolation (optional)
        if run_inpmat:
            print("\n" + "-" * 70)
            print("Step 4: generate_inpmat (create runoff interpolation matrix)")
            print("-" * 70)

            # Get input matrix configuration from INPMAT section
            grsizein = nml.get('RiverMap_Gen', 'grsizein', 0.25)
            westin = nml.get('RiverMap_Gen', 'westin', west)
            eastin = nml.get('RiverMap_Gen', 'eastin', east)
            northin = nml.get('RiverMap_Gen', 'northin', north)
            southin = nml.get('RiverMap_Gen', 'southin', south)
            olat = nml.get('RiverMap_Gen', 'olat', 'NtoS')

            # Fixed filenames based on case name
            diminfo_file = os.path.join(output_dir, f'diminfo_15min_{case_name}.txt')
            inpmat_file = os.path.join(output_dir, f'inpmat_15min_{case_name}.bin')

            # Get hires tag from RIVER_PARAMS section (default: 1min)
            hires_tag = nml.get('RiverMap_Gen', 'hires_tag', '1min')

            param_proc = ParamProcessor(config=nml)
            param_proc.generate_inpmat(
                map_dir=output_dir,
                hires_tag=hires_tag,
                gsizein=grsizein,
                westin=westin,
                eastin=eastin,
                northin=northin,
                southin=southin,
                olat=olat,
                diminfo_file=diminfo_file,
                inpmat_file=inpmat_file
            )

        print("\n✓ Region generation completed successfully!")
        return True

    except Exception as e:
        print(f"\n✗ ERROR in region generation: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_param_generation(nml, output_dir, case_name, global_map_dir, run_bifurcation=False, run_prmwat=False):
    """
    Generate parameter files
    Equivalent to: calc_outclm + calc_rivwth + set_gwdlr + [calc_prmwat] + [set_bifparam]
    """
    header_text = "PARAMETER GENERATION (calc_outclm + calc_rivwth + set_gwdlr"
    if run_prmwat:
        header_text += " + calc_prmwat"
    if run_bifurcation:
        header_text += " + set_bifparam"
    header_text += ")"
    print_header(header_text)

    # Get runoff configuration from RIVER_PARAMS
    runoff_file = nml.get('RiverMap_Gen', 'runoff_file')
    runoff_var = nml.get('RiverMap_Gen', 'runoff_var', 'ro')

    # Resolve paths relative to current directory
    if not os.path.isabs(runoff_file):
        runoff_file = os.path.abspath(runoff_file)

    # Use auto-generated inpmat and diminfo files
    diminfo_file = os.path.join(output_dir, f'diminfo_15min_{case_name}.txt')
    inpmat_file = os.path.join(output_dir, f'inpmat_15min_{case_name}.bin')

    print(f"\nRunoff file: {runoff_file}")
    print(f"Runoff variable: {runoff_var}")
    print(f"Input matrix: {inpmat_file}")
    print(f"Dimension info: {diminfo_file}")

    # Check required files exist (generated by region generation)
    required_files = ['nextxy.bin', 'ctmare.bin', 'width.bin', 'params.txt',
                     os.path.basename(diminfo_file), os.path.basename(inpmat_file)]
    for fname in required_files:
        fpath = os.path.join(output_dir, fname)
        if not os.path.exists(fpath):
            print(f"\n✗ ERROR: Required file not found: {fpath}")
            print("Please run region generation first.")
            return False

    # Initialize processor
    param_proc = ParamProcessor(config=None)

    # Get river parameters
    channel = nml.get_section('RIVER_PARAMS')
    HC = channel.get('hc', 0.1)
    HP = channel.get('hp', 0.5)
    HO = channel.get('ho', 0.0)
    HMIN = channel.get('hmin', 1.0)
    WC = channel.get('wc', 2.5)
    WP = channel.get('wp', 0.60)
    WO = channel.get('wo', 0.0)
    WMIN = channel.get('wmin', 5.0)

    print(f"\nChannel parameters:")
    print(f"  Height: H = max({HMIN}, {HC} * Q^{HP} + {HO})")
    print(f"  Width:  W = max({WMIN}, {WC} * Q^{WP} + {WO})")

    try:
        # Step 1: Generate outclm.bin (discharge climatology)
        print("\n" + "-" * 70)
        print("Step 1/3: calc_outclm (discharge climatology)")
        print("-" * 70)
        param_proc.calc_outclm(
            map_dir=output_dir,
            runoff_file=runoff_file,
            diminfo_file=diminfo_file,
            data_type='cdf',
            runoff_var=runoff_var
        )

        # Step 2: Generate river width/height parameters
        print("\n" + "-" * 70)
        print("Step 2/3: calc_rivwth (channel geometry)")
        print("-" * 70)
        param_proc.calc_rivwth(
            map_dir=output_dir,
            HC=HC, HP=HP, HO=HO, HMIN=HMIN,
            WC=WC, WP=WP, WO=WO, WMIN=WMIN
        )

        # Step 3: Merge with satellite width
        print("\n" + "-" * 70)
        print("Step 3: set_gwdlr (merge satellite width)")
        print("-" * 70)
        param_proc.set_gwdlr(map_dir=output_dir)

        # Step 4: Calculate permanent water area (optional)
        step_num = 4
        if run_prmwat:
            print("\n" + "-" * 70)
            print(f"Step {step_num}: calc_prmwat (permanent water area)")
            print("-" * 70)

            # Get hires_tag from RIVER_PARAMS
            hires_tag = nml.get('RiverMap_Gen', 'hires_tag', '1min')

            # Copy high-resolution directory from global map if needed
            # Default source: global_map_dir/{hires_tag}
            hires_dst = os.path.join(output_dir, hires_tag)
            if not os.path.exists(hires_dst):
                hires_src = os.path.join(global_map_dir, hires_tag)
                if os.path.exists(hires_src):
                    print(f"Copying high-resolution data from {hires_src}...")
                    shutil.copytree(hires_src, hires_dst)
                else:
                    print(f"WARNING: High-resolution data not found at {hires_src}")

            param_proc.calc_prmwat(
                map_dir=output_dir,
                hires_tag=hires_tag
            )
            step_num += 1

        # Step 5: Generate bifurcation parameters (optional)
        if run_bifurcation:
            print("\n" + "-" * 70)
            print(f"Step {step_num}: set_bifparam (bifurcation parameters)")
            print("-" * 70)

            # Priority order for bifori.txt:
            # 1. Use regionalized bifori.txt from output_dir (generated by cut_bifway)
            # 2. Fall back to global bifori.txt from global_map_dir
            # 3. If specified in namelist, use that as final fallback
            bifori_file = os.path.join(output_dir, 'bifori.txt')

            if not os.path.exists(bifori_file):
                print(f"WARNING: Generated bifori.txt not found at {bifori_file}")
                print(f"         Trying global bifori.txt from global_map_dir...")
                bifori_file = os.path.join(global_map_dir, 'bifori.txt')

                if not os.path.exists(bifori_file):
                    print(f"WARNING: Global bifori.txt not found at {bifori_file}")
                    print(f"         Trying bifori_file from namelist...")
                    bifori_file_nml = nml.get('RiverMap_Gen', 'bifori_file', None)
                    if bifori_file_nml:
                        if not os.path.isabs(bifori_file_nml):
                            bifori_file = os.path.abspath(bifori_file_nml)
                        else:
                            bifori_file = bifori_file_nml
                    else:
                        raise FileNotFoundError(
                            f"bifori.txt not found in:\n"
                            f"  - Output dir: {output_dir}/bifori.txt\n"
                            f"  - Global map dir: {global_map_dir}/bifori.txt\n"
                            f"Please run cut_bifway first or ensure bifori.txt exists in global_map_dir."
                        )

            print(f"Using bifori file: {bifori_file}")
            nlev_new = nml.get('RiverMap_Gen', 'nlev_new', 5)

            param_proc.set_bifparam(
                map_dir=output_dir,
                bifori_file=bifori_file,
                nlev_new=nlev_new
            )

        print("\n✓ Parameter generation completed successfully!")
        return True

    except Exception as e:
        traceback.print_exc()
        return False

def execute_dam_allocation(nml, output_dir):
    """
    Allocate dams to the river network
    """
    print_header("DAM ALLOCATION")

    # Initialize processor and call allocate_dams
    try:
        param_proc = ParamProcessor(config=nml) # Pass the namelist object as config
        param_proc.allocate_dams(output_dir)
        print("\n✓ Dam allocation completed successfully!")
        return True
    except Exception as e:
        traceback.print_exc()
        return False

def execute_dam_param_calculation(nml, output_dir):
    """
    Calculate dam parameters.
    """
    print_header("DAM PARAMETER CALCULATION")

    try:
        # Create a temporary directory for intermediate files
        temp_dir = os.path.join(output_dir, 'dam_param_temp')
        os.makedirs(temp_dir, exist_ok=True)

        # Initialize processor
        from .dam_param_tools import DamParamProcessor
        dam_proc = DamParamProcessor(config=nml)

        # Run the pipeline
        dam_proc.calc_annual_max_mean(output_dir, temp_dir)
        dam_proc.calc_100yr_discharge(output_dir, temp_dir)
        dam_proc.est_fldsto_surfacearea(output_dir, temp_dir)
        dam_proc.complete_dam_csv(output_dir, temp_dir)

        # Finalize the dam_param.csv file
        final_dam_param_file = os.path.join(output_dir, 'dam_param.csv')
        temp_dam_param_file = os.path.join(temp_dir, 'tmp_p04_damparams.csv')
        
        with open(temp_dam_param_file, 'r') as f:
            lines = f.readlines()
            ndams = len(lines) - 1

        with open(final_dam_param_file, 'w') as f_out:
            f_out.write(f'{ndams},NDAMS\n')
            f_out.writelines(lines)

        print(f'Final dam parameter file created: {final_dam_param_file}')

        # Clean up temporary directory
        # shutil.rmtree(temp_dir)

        print("\n✓ Dam parameter calculation completed successfully!")
        return True
    except Exception as e:
        print(f"\n✗ ERROR in dam parameter calculation: {e}")
        import traceback
        traceback.print_exc()
        return False




def main():
    """Main program"""
    parser = argparse.ArgumentParser(
        description='Grid Routing Initialization - Generate region and parameter files',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python workflow.py                    # Use default namelist.input
  python workflow.py namelist.input     # Use specified namelist
  python workflow.py custom.nml         # Use custom namelist
  python workflow.py namelist.input --region-only   # Only generate region files
  python workflow.py namelist.input --params-only   # Only generate parameter files
        """
    )
    parser.add_argument('namelist', nargs='?', default='namelist.input',
                        help='Namelist file path (default: namelist.input)')
    parser.add_argument('--region-only', action='store_true',
                        help='Only run region generation')
    parser.add_argument('--params-only', action='store_true',
                        help='Only run parameter generation')
    args = parser.parse_args()

    # Print banner
    print("=" * 70)
    print("GRID ROUTING INITIALIZATION")
    print("Python implementation of CaMa-Flood map generation")
    print("=" * 70)

    # Read namelist
    print(f"\nReading namelist: {args.namelist}")
    try:
        nml = Namelist(args.namelist)
    except Exception as e:
        print(f"ERROR: Failed to read namelist: {e}")
        return 1

    # Get output configuration
    output_base_dir = nml.get('OUTPUT', 'output_base_dir', './output')
    case_name = nml.get('OUTPUT', 'case_name', 'default')

    # Construct output directory from base + case name
    output_dir = os.path.join(output_base_dir, case_name)

    # Get global map directory from RiverMap_Gen
    global_map_dir = nml.get('RiverMap_Gen', 'global_map_dir')

    # Resolve relative paths
    if not os.path.isabs(global_map_dir):
        global_map_dir = os.path.abspath(global_map_dir)
    if not os.path.isabs(output_dir):
        output_dir = os.path.abspath(output_dir)

    # DOMAIN configuration is required for region generation
    # Region generation will run if DOMAIN is properly configured
    run_region = True  # Always attempt region generation (requires DOMAIN)

    # Get other options
    run_inpmat = nml.get('RiverMap_Gen', 'run_inpmat', True)
    run_params = nml.get('RiverMap_Gen', 'run_params', True)
    run_prmwat = nml.get('RiverMap_Gen', 'run_prmwat', False)
    run_bifurcation = nml.get('RiverMap_Gen', 'run_bifurcation', False)
    run_dam = nml.get('RiverMap_Gen', 'run_dam', False)

    # run_dam controls both dam allocation and parameter calculation
    run_dam_allocation = run_dam
    run_dam_param_calculation = run_dam

    # Override with command line arguments
    if args.region_only:
        run_region = True
        run_params = False
        run_prmwat = False
        run_bifurcation = False
    if args.params_only:
        run_region = False
        run_params = True
        # run_prmwat and run_bifurcation keep their namelist values

    print(f"\nConfiguration:")
    print(f"  Case name: {case_name}")
    print(f"  Global map: {global_map_dir}")
    print(f"  Output: {output_dir}")
    print(f"  Run region generation: {run_region}")
    print(f"  Run input matrix generation: {run_inpmat}")
    print(f"  Run parameter generation: {run_params}")
    print(f"  Run permanent water calculation: {run_prmwat}")
    print(f"  Run bifurcation generation: {run_bifurcation}")
    print(f"  Run dam allocation: {run_dam_allocation}")
    print(f"  Run dam parameter calculation: {run_dam_param_calculation}")

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    # Run tasks
    success = True

    if run_region:
        if not run_region_generation(nml, global_map_dir, output_dir, case_name, run_bifurcation, run_inpmat):
            success = False

    if run_params and success:
        if not run_param_generation(nml, output_dir, case_name, global_map_dir, run_bifurcation, run_prmwat):
            success = False

    if run_dam_allocation and success:
        if not execute_dam_allocation(nml, output_dir):
            success = False

    if run_dam_param_calculation and success:
        if not execute_dam_param_calculation(nml, output_dir):
            success = False

    # Summary
    print_header("SUMMARY")
    if success:
        print("\n✓ All tasks completed successfully!")
        print(f"\nOutput files: {output_dir}")

        # List generated files
        files = sorted([f for f in os.listdir(output_dir)
                       if f.endswith('.bin') or f.endswith('.txt')])
        print(f"\nGenerated {len(files)} files:")
        for f in files:
            size_kb = os.path.getsize(os.path.join(output_dir, f)) / 1024
            if size_kb < 1:
                print(f"  - {f}")
            else:
                print(f"  - {f} ({size_kb:.1f} KB)")

        print("\n" + "=" * 70)
        return 0
    else:
        print("\n✗ Some tasks failed. Please check the errors above.")
        print("=" * 70)
        return 1


if __name__ == '__main__':
    sys.exit(main())
